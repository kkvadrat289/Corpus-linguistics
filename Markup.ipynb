{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "path = '../posts/'\n",
    "filenames = [name for name in os.listdir(path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "df = read_csv('./risk/posts_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 33863 entries, 0 to 33862\n",
      "Data columns (total 13 columns):\n",
      "Unnamed: 0      33863 non-null int64\n",
      "ID              33863 non-null object\n",
      "author          33863 non-null object\n",
      "date            33863 non-null object\n",
      "img             33863 non-null bool\n",
      "rating          33863 non-null int64\n",
      "tag_activity    30506 non-null object\n",
      "tag_category    20381 non-null object\n",
      "tag_group       6556 non-null object\n",
      "tag_place       4463 non-null object\n",
      "tag_xtype       1638 non-null object\n",
      "title           33863 non-null object\n",
      "video           33863 non-null bool\n",
      "dtypes: bool(2), int64(2), object(9)\n",
      "memory usage: 2.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>img</th>\n",
       "      <th>rating</th>\n",
       "      <th>tag_activity</th>\n",
       "      <th>tag_category</th>\n",
       "      <th>tag_group</th>\n",
       "      <th>tag_place</th>\n",
       "      <th>tag_xtype</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>blog-215386.txt</td>\n",
       "      <td>/people/kate10</td>\n",
       "      <td>10.10.2018</td>\n",
       "      <td>True</td>\n",
       "      <td>25</td>\n",
       "      <td>Альпинизм</td>\n",
       "      <td>Новости</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Жетон \"Спасение в Горах\" снова в Москве</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>blog-215345.txt</td>\n",
       "      <td>/people/redakciyasajta</td>\n",
       "      <td>03.10.2018</td>\n",
       "      <td>True</td>\n",
       "      <td>77</td>\n",
       "      <td>Воздух</td>\n",
       "      <td>Взаимопомощь</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Леониду Мартынову нужна помощь!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>blog-215348.txt</td>\n",
       "      <td>/people/redakciyasajta</td>\n",
       "      <td>03.10.2018</td>\n",
       "      <td>True</td>\n",
       "      <td>73</td>\n",
       "      <td>Альпинизм</td>\n",
       "      <td>Новости</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Виталий и Антон возвращаются!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>blog-215335.txt</td>\n",
       "      <td>/people/robinsya</td>\n",
       "      <td>02.10.2018</td>\n",
       "      <td>True</td>\n",
       "      <td>88</td>\n",
       "      <td>Альпинизм</td>\n",
       "      <td>Помним</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Марафон памяти – марафон дружбы</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>blog-215186.txt</td>\n",
       "      <td>/people/sergeyglaznov</td>\n",
       "      <td>05.09.2018</td>\n",
       "      <td>True</td>\n",
       "      <td>253</td>\n",
       "      <td>Альпинизм</td>\n",
       "      <td>Новости</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Хочу заступиться за Пакистанцев!</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               ID                  author        date   img  \\\n",
       "0           0  blog-215386.txt          /people/kate10  10.10.2018  True   \n",
       "1           1  blog-215345.txt  /people/redakciyasajta  03.10.2018  True   \n",
       "2           2  blog-215348.txt  /people/redakciyasajta  03.10.2018  True   \n",
       "3           3  blog-215335.txt        /people/robinsya  02.10.2018  True   \n",
       "4           4  blog-215186.txt   /people/sergeyglaznov  05.09.2018  True   \n",
       "\n",
       "   rating tag_activity  tag_category tag_group tag_place tag_xtype  \\\n",
       "0      25    Альпинизм       Новости       NaN       NaN       NaN   \n",
       "1      77       Воздух  Взаимопомощь       NaN       NaN       NaN   \n",
       "2      73    Альпинизм       Новости       NaN       NaN       NaN   \n",
       "3      88    Альпинизм        Помним       NaN       NaN       NaN   \n",
       "4     253    Альпинизм       Новости       NaN       NaN       NaN   \n",
       "\n",
       "                                     title  video  \n",
       "0  Жетон \"Спасение в Горах\" снова в Москве  False  \n",
       "1          Леониду Мартынову нужна помощь!  False  \n",
       "2            Виталий и Антон возвращаются!  False  \n",
       "3          Марафон памяти – марафон дружбы  False  \n",
       "4         Хочу заступиться за Пакистанцев!  False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем, что нет лишних или недостающих файлов\n",
    "assert(len(set(filenames).intersection(set(df['ID']))) == len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Токенизация корпуса\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сегментация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/russian.pickle')\n",
    "coords = dict()\n",
    "for name in filenames:\n",
    "    with open(path + name, 'r') as f:\n",
    "        coords[name] = '\\n'.join([str(span) for span in tokenizer.span_tokenize(f.read())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "\n",
    "df_markup = DataFrame.from_dict(coords, orient='index',columns=['coords_sent'])\n",
    "df_sent.to_csv('./sentences.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_count = 0\n",
    "for coords in df_markup['coords_sent']:\n",
    "    sentence_count += len(coords.split('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1016341"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Количество предложений в корпусе:\n",
    "sentence_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Токенизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = nltk.word_tokenize(text, 'russian')\n",
    "    tokens = [word.lower() for word in tokens if ( word not in string.punctuation + '«»–' )]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = set()\n",
    "words_count = 0\n",
    "for name in filenames:\n",
    "    tokens = tokenize(open(path + name, 'r').read())\n",
    "    words.update(tokens)\n",
    "    words_count += len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего слов:  13348440\n",
      "Различных слов:  544005\n"
     ]
    }
   ],
   "source": [
    "print('Всего слов: ', words_count)\n",
    "print('Различных слов: ', len(words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS-tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pymorphy2\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tag(tag):\n",
    "    tags_dict = dict()\n",
    "    tags_dict['POS'] = tag.POS\n",
    "    tags_dict['animacy'] = tag.animacy\n",
    "    tags_dict['aspect'] = tag.aspect        # вид: совершенный или несовершенный\n",
    "    tags_dict['case'] = tag.case          # падеж\n",
    "    tags_dict['gender'] = tag.gender        # род (мужской, женский, средний)\n",
    "    tags_dict['involvement'] = tag.involvement   # включенность говорящего в действие\n",
    "    tags_dict['mood'] = tag.mood          # наклонение (повелительное, изъявительное)\n",
    "    tags_dict['number'] = tag.number        # число (единственное, множественное)\n",
    "    tags_dict['person'] = tag.person        # лицо (1, 2, 3)\n",
    "    tags_dict['tense'] = tag.tense         # время (настоящее, прошедшее, будущее)\n",
    "    tags_dict['transitivity'] = tag.transitivity  # переходность (переходный, непереходный)\n",
    "    tags_dict['voice'] = tag.voice         # залог (действительный, страдательный)\n",
    "    return {k:v for k,v in tags_dict.items() if v is not None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morph = pymorphy2.MorphAnalyzer()\n",
    "tags = dict()\n",
    "for name in filenames:\n",
    "    with open(path + name, 'r') as f:\n",
    "        tokens = [x for x in tokenize(f.read()) if x not in list(string.punctuation + '«»–')]\n",
    "        tags = {word:tag for word, tag in zip(tokens, [parse_tag(morph.tag(word)[0]) for word in tokens]) if len(tag) > 0}\n",
    "        with open('../Markup/' + name.replace('txt', 'json'), 'w') as f:\n",
    "            f.write(json.dumps(tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = pymorphy2.tagset.OpencorporaTag\n",
    "morph_path = '../Markup/'\n",
    "CASES = tag.CASES\n",
    "case_count = {k:v for k, v in zip(list(CASES),np.zeros(len(CASES)))}\n",
    "POS = tag.PARTS_OF_SPEECH\n",
    "pos_count =  {k:v for k, v in zip(list(POS),np.zeros(len(POS)))}\n",
    "TENSE = list(tag.TENSES)\n",
    "tense_count = {k:v for k, v in zip(TENSE, np.zeros(len(TENSE)))}\n",
    "voice_count = {k:v for k,v in zip(tag.VOICES, np.zeros(len(tag.VOICES)))}\n",
    "total = 0\n",
    "for name in os.listdir(morph_path)[1:]:\n",
    "    with open(morph_path + name, 'r') as f:\n",
    "        d = json.load(f)\n",
    "        for key, value in d.items():\n",
    "            if 'case' in value:\n",
    "                case_count[value['case']] += 1\n",
    "            if 'POS' in value:\n",
    "                pos_count[value['POS']] += 1\n",
    "            if 'tense' in value:\n",
    "                tense_count[value['tense']] += 1\n",
    "            if 'voice' in value:\n",
    "                voice_count[value['voice']] += 1\n",
    "            total += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('loc1', 0.0),\n",
       " ('acc2', 0.0),\n",
       " ('gen1', 0.0),\n",
       " ('voct', 8.72685665895525e-05),\n",
       " ('gen2', 0.0002976289076588133),\n",
       " ('loc2', 0.00224878167424745),\n",
       " ('datv', 0.039586260803188646),\n",
       " ('ablt', 0.05108416379878993),\n",
       " ('loct', 0.05676981865107037),\n",
       " ('accs', 0.06698051028947576),\n",
       " ('gent', 0.1999395584372139),\n",
       " ('nomn', 0.21909110326591835)]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "case_count_ = sorted(case_count.items(), key=lambda x: x[1])\n",
    "[(k, v/total) for k, v in case_count_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('INTJ', 0.0024081006777589326),\n",
       " ('PRED', 0.0040152967791165246),\n",
       " ('COMP', 0.0056000023702573645),\n",
       " ('NUMR', 0.006249533692265716),\n",
       " ('PRTS', 0.006930713337034167),\n",
       " ('GRND', 0.00860363021076167),\n",
       " ('ADJS', 0.011129435714445399),\n",
       " ('PRTF', 0.014478905652174967),\n",
       " ('PRCL', 0.01610522542090249),\n",
       " ('NPRO', 0.02656465940883088),\n",
       " ('CONJ', 0.028705567438266244),\n",
       " ('INFN', 0.0392783966932755),\n",
       " ('PREP', 0.03963811018302966),\n",
       " ('ADVB', 0.06500040267440448),\n",
       " ('VERB', 0.1365000241065948),\n",
       " ('ADJF', 0.16401265178737606),\n",
       " ('NOUN', 0.4247793438535052)]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v/total) for k, v in sorted(pos_count.items(), key=lambda x: x[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenses = 0\n",
    "for item in tense_count.values():\n",
    "    tenses += int(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('futr', 0.08180737680329876),\n",
       " ('pres', 0.3492923010067827),\n",
       " ('past', 0.5689003221899186)]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[(k, v/tenses) for k, v in sorted(tense_count.items(), key=lambda x: x[1])]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
